{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de Decisão - Random Forest - Crédito Bancário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disponível em: https://mkmanu.wordpress.com/2014/08/28/modelling-credit-score-in-r-part-1/\n",
    "\n",
    "Classe:\n",
    "Credito: 0 - não concedido, 1 - concedido\n",
    "\n",
    "Atributos:\n",
    "\n",
    "duraçao_emprestimo: em meses\n",
    "\n",
    "tempo_de_residencia: em anos\n",
    "\n",
    "Quantidade_emprestimo: em Reais\n",
    "\n",
    "Idade: em anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"credito.csv\")\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tamanho do dataset: \",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlação\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Credito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Credito.value_counts() # Credito: 0 - não concedido, 1 - concedido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera os dados de treino\n",
    "\n",
    "X = df.loc[:,[\"duracao_emprestimo\", \"tempo_de_residencia\", \"Quantidade_Emprestimo\", \"idade\"]]\n",
    "y = df.loc[:,[\"Credito\"]].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo - Arvore de Decisao\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = clf.fit(X_train, Y_train)\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (accuracy_score(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colocar em escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "X_train_std[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = clf.fit(X_train_std, Y_train)\n",
    "previsoes = modelo.predict(X_test_std)\n",
    "print (confusion_matrix(Y_test, previsoes))\n",
    "print (accuracy_score(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando o Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators  = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os 4 principais parâmetros em Modelos de Random Forest são:\n",
    "\n",
    "n_estimators - quanto maior, melhor!\n",
    "\n",
    "max depth - o padrão é 'none' e nesse caso árvores completas são criadas. Ajustando esse parâmetro pode ajudar a evitar overfitting.\n",
    "\n",
    "max_features - diferentes valores devem ser testados, pois este parâmetro impacta na forma como os modelos RF distribuem os atributos pelas árvores.\n",
    "\n",
    "criterion - define a forma como o algoritmo fará a divisão dos atributos e a classificação dos nós em cada árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo\n",
    "modelo = clf.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previsoes = modelo.predict(XTest)\n",
    "# Create random forest classifier instance\n",
    "predictions = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo.score(XTest, predictions)\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Train Accuracy :: \", accuracy_score(Y_train, modelo.predict(X_train)))\n",
    "print (\"Test Accuracy  :: \", accuracy_score(Y_test, predictions))\n",
    "print (\" Confusion matrix :: \\n \", confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previsao de uma instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = X_train[0:1]\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.predict(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.predict_proba(instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x% de Negar crédito e y% de Aceitar Crédito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo a Importância dos Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo a importância\n",
    "atributos = [\"duracao_emprestimo\", \"tempo_de_residencia\", \"Quantidade_Emprestimo\", \"idade\"]\n",
    "importances = modelo.feature_importances_\n",
    "print(atributos)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[atributos, list(importances)])\n",
    "df = df.T\n",
    "df.columns = ['atributos', 'importância']\n",
    "df = df.sort_values('importância', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotar os atributos e suas importancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.style.use('ggplot')\n",
    "plt.yticks(np.arange(len(df)), df.atributos)\n",
    "plt.title('Importância dos Atributos')\n",
    "plt.barh(range(len(df)), df['importância'], color = 'g', align = 'center')\n",
    "#plt.yticks(range(len(indices)),ind)\n",
    "plt.xlabel('Importância Relativa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do Classificador\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cross_val_score - Evaluate a score by cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo\n",
    "scores = cross_val_score(bagging, X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média do score\n",
    "mean = scores.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do Classificador\n",
    "bagging = BaggingClassifier(RandomForestClassifier(n_estimators  = 5000), max_samples = 0.5, max_features = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo\n",
    "scores = cross_val_score(bagging, X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média do score\n",
    "mean = scores.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees (ExtraTrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o classificador\n",
    "clf = DecisionTreeClassifier(max_depth = None, min_samples_split = 2, random_state = 0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 10, max_depth = None, min_samples_split = 2, \n",
    "                             random_state = 0)\n",
    "scores = cross_val_score(clf, X, y.ravel())\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators = 10, max_depth = None, min_samples_split = 2, random_state = 0)\n",
    "scores = cross_val_score(clf, X, y.ravel())\n",
    "mean = scores.mean()\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o estimador base\n",
    "estim_base = DecisionTreeClassifier(max_depth = 1, min_samples_leaf = 1)\n",
    "estim_base.fit(X_train, Y_train)\n",
    "print(estim_base.score(X_test, Y_test))\n",
    "estim_base_err = 1.0 - estim_base.score(X_test, Y_test)\n",
    "estim_base_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(base_estimator = estim_base, \n",
    "                                  learning_rate = 0.07, \n",
    "                                  n_estimators = 400, \n",
    "                                  algorithm = \"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(ada_clf, X_test, Y_test.ravel())\n",
    "print(scores)\n",
    "means = scores.mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting = Gradient Descent + Boosting. \n",
    "\n",
    "Basicamente 3 etapas são realizadas na construção do modelo:\n",
    "\n",
    "1- Gera um regressor\n",
    "\n",
    "2- Computa o erro residual\n",
    "\n",
    "3- Aprende a prever o resíduo\n",
    "\n",
    "\n",
    "\n",
    "Parâmetros mais importantes:\n",
    "\n",
    "Número de árvores de regressão (n_estimators)\n",
    "\n",
    "Profundidade de cara árvore (max_depth)\n",
    "\n",
    "loss function (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como funciona o Gradient Boosting: <br>\n",
    "1 - Realiza um conjunto de previsões (y)\n",
    "\n",
    "2- Calcula o erro das previsões ( j )\n",
    "\n",
    "3- Tenta ajustar y reduzindo o erro (através de alpha)\n",
    "\n",
    "4- Para cada estimador base, é estimado o gradiente da função de perda\n",
    "\n",
    "5- Estimadores subsequentes estimam o erro residual dos estimadores anteriores\n",
    "\n",
    "6- Aplica o Gradient Descent para reduzir j\n",
    "\n",
    "7- Soma os resultados dos estimadores, dando peso a cada passo de acordo com o valor de alfa\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting\n",
    "\n",
    "Gradient Boosting Classifier\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Cria o classificador\n",
    "est = GradientBoostingClassifier(n_estimators = 600, max_depth = 3)\n",
    "\n",
    "# Cria o modelo\n",
    "est.fit(X_train, Y_train.ravel())\n",
    "\n",
    "# Previsões das classes (labels)\n",
    "pred = est.predict(X_test)\n",
    "\n",
    "# Score nos dados de teste (Acurácia)\n",
    "acc = est.score(X_test, Y_test.ravel())\n",
    "print('Acurácia: %.4f' % acc)\n",
    "\n",
    "# Previsão das probabilidades das classes\n",
    "est.predict_proba(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - Algoritmo Ensemble Mais Eficiente\n",
    "\n",
    "### Regularização (controla a complexidade, Reduz o Overfitting) ###\n",
    "### Objective Function : Training Loss + Regularization ###\n",
    "### Usa processamento paralelo (Roda no Spark) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXtreme Gradient Boosting (XGBoost)\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/\n",
    "\n",
    "O XGBoost é uma biblioteca otimizada de aumento de gradiente distribuído, <br>\n",
    "projetada para ser altamente eficiente, flexível e portátil. <br>\n",
    "Ele implementa algoritmos de aprendizado de máquina sob a estrutura Gradient Boosting. <br>\n",
    "O XGBoost fornece um aumento de árvore paralelo (também conhecido como GBDT, GBM) que resolve muitos <br>\n",
    "problemas de Ciência de Dados de maneira rápida e precisa. <br>\n",
    "O mesmo código é executado no ambiente distribuído (Hadoop, SGE, MPI) e <br>\n",
    "pode resolver problemas com dados de bilhões de registros.<br><br>\n",
    "\n",
    "Amplamente usado nas competições do Kaggle.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instalar no prompt de comando\n",
    "#!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train.ravel())\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv')\n",
    "dataset.columns = [ \"preg\", \"glucose\", \"Diastolic\", \"Triceps\", \"insulin\", \"BDI\", \"ped_func\", \"Age\", \"Class\"]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = dataset.iloc[:,0:8]\n",
    "Y = dataset.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"XGBoost\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(), max_samples = 0.5, max_features = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo\n",
    "scores = cross_val_score(bagging, X, Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bagging\")\n",
    "means = scores.mean()\n",
    "print(\"Accuracy: %.2f%%\" % (means * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
