{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "ACCESS_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "ACCESS_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-2-7ff5d90695ff>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-7ff5d90695ff>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    print 'out of depth'\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "FOLLOWING_DIR = 'following'\n",
    "MAX_FRIENDS = 200\n",
    "FRIENDS_OF_FRIENDS_LIMIT = 200\n",
    "\n",
    "#if not os.path.exists(FOLLOWING_DIR):\n",
    "#    os.makedir(\"c://tmp//twitter_python\")\n",
    "\n",
    "enc = lambda x: x.encode('ascii', errors='ignore')\n",
    "\n",
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "ACCESS_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "ACCESS_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'\n",
    "\n",
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print (api)\n",
    "\n",
    "def get_follower_ids(centre, max_depth=1, current_depth=0, taboo_list=[]):\n",
    "\n",
    "    # print 'current depth: %d, max depth: %d' % (current_depth, max_depth)\n",
    "    # print 'taboo list: ', ','.join([ str(i) for i in taboo_list ])\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        print 'out of depth'\n",
    "        return taboo_list\n",
    "\n",
    "    if centre in taboo_list:\n",
    "        # we've been here before\n",
    "        print 'Already been here.'\n",
    "        return taboo_list\n",
    "    else:\n",
    "        taboo_list.append(centre)\n",
    "\n",
    "    try:\n",
    "        userfname = os.path.join('twitter-users', str(centre) + '.json')\n",
    "        if not os.path.exists(userfname):\n",
    "            print 'Retrieving user details for twitter id %s' % str(centre)\n",
    "            while True:\n",
    "                try:\n",
    "                    user = api.get_user(centre)\n",
    "\n",
    "                    d = {'name': user.name,\n",
    "                         'screen_name': user.screen_name,\n",
    "                         'id': user.id,\n",
    "                         'friends_count': user.friends_count,\n",
    "                         'followers_count': user.followers_count,\n",
    "                         'followers_ids': user.followers_ids()}\n",
    "\n",
    "                    with open(userfname, 'w') as outf:\n",
    "                        outf.write(json.dumps(d, indent=1))\n",
    "\n",
    "                    user = d\n",
    "                    break\n",
    "                except tweepy.TweepError, error:\n",
    "                    print type(error)\n",
    "\n",
    "                    if str(error) == 'Not authorized.':\n",
    "                        print 'Can''t access user data - not authorized.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    if str(error) == 'User has been suspended.':\n",
    "                        print 'User suspended.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    errorObj = error[0][0]\n",
    "\n",
    "                    print errorObj\n",
    "\n",
    "                    if errorObj['message'] == 'Rate limit exceeded':\n",
    "                        print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "\n",
    "                    return taboo_list\n",
    "        else:\n",
    "            user = json.loads(file(userfname).read())\n",
    "\n",
    "        screen_name = enc(user['screen_name'])\n",
    "        fname = os.path.join(FOLLOWING_DIR, screen_name + '.csv')\n",
    "        friendids = []\n",
    "\n",
    "        # only retrieve friends of TED... screen names\n",
    "        if screen_name.startswith('TED'):\n",
    "            if not os.path.exists(fname):\n",
    "                print 'No cached data for screen name \"%s\"' % screen_name\n",
    "                with open(fname, 'w') as outf:\n",
    "                    params = (enc(user['name']), screen_name)\n",
    "                    print 'Retrieving friends for user \"%s\" (%s)' % params\n",
    "\n",
    "                    # page over friends\n",
    "                    c = tweepy.Cursor(api.friends, id=user['id']).items()\n",
    "\n",
    "                    friend_count = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            friend = c.next()\n",
    "                            friendids.append(friend.id)\n",
    "                            params = (friend.id, enc(friend.screen_name), enc(friend.name))\n",
    "                            outf.write('%s\\t%s\\t%s\\n' % params)\n",
    "                            friend_count += 1\n",
    "                            if friend_count >= MAX_FRIENDS:\n",
    "                                print 'Reached max no. of friends for \"%s\".' % friend.screen_name\n",
    "                                break\n",
    "                        except tweepy.TweepError:\n",
    "                            # hit rate limit, sleep for 15 minutes\n",
    "                            print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                            time.sleep(15 * 60 + 15)\n",
    "                            continue\n",
    "                        except StopIteration:\n",
    "                            break\n",
    "            else:\n",
    "                friendids = [int(line.strip().split('\\t')[0]) for line in file(fname)]\n",
    "\n",
    "            print 'Found %d friends for %s' % (len(friendids), screen_name)\n",
    "\n",
    "            # get friends of friends\n",
    "            cd = current_depth\n",
    "            if cd+1 < max_depth:\n",
    "                for fid in friendids[:FRIENDS_OF_FRIENDS_LIMIT]:\n",
    "                    taboo_list = get_follower_ids(fid, max_depth=max_depth,\n",
    "                        current_depth=cd+1, taboo_list=taboo_list)\n",
    "\n",
    "            if cd+1 < max_depth and len(friendids) > FRIENDS_OF_FRIENDS_LIMIT:\n",
    "                print 'Not all friends retrieved for %s.' % screen_name\n",
    "\n",
    "    except Exception, error:\n",
    "        print 'Error retrieving followers for user id: ', centre\n",
    "        print error\n",
    "\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "            print 'Removed file \"%s\".' % fname\n",
    "\n",
    "        sys.exit(1)\n",
    "\n",
    "    return taboo_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-s\", \"--screen-name\", required=True, help=\"Screen name of twitter user\")\n",
    "    ap.add_argument(\"-d\", \"--depth\", required=True, type=int, help=\"How far to follow user network\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    twitter_screenname = args['screen_name']\n",
    "#     depth = int(args['depth'])\n",
    "\n",
    "#     if depth < 1 or depth > 3:\n",
    "#         print 'Depth value %d is not valid. Valid range is 1-3.' % depth\n",
    "#         sys.exit('Invalid depth argument.')\n",
    "\n",
    "#     print 'Max Depth: %d' % depth\n",
    "    matches = api.lookup_users(screen_names=[twitter_screenname])\n",
    "    \n",
    "    depth = 3\n",
    "    print get_follower_ids(matches[0].id, max_depth=depth)\n",
    "    \n",
    "#     if len(matches) == 1:\n",
    "#         print get_follower_ids(matches[0].id, max_depth=depth)\n",
    "#     else:\n",
    "#         print 'Sorry, could not find twitter user with screen name: %s' % twitter_screenname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e3c9606dab32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "FOLLOWING_DIR = 'following'\n",
    "MAX_FRIENDS = 200\n",
    "FRIENDS_OF_FRIENDS_LIMIT = 200\n",
    "\n",
    "#if not os.path.exists(FOLLOWING_DIR):\n",
    "#    os.makedir(\"c://tmp//twitter_python\")\n",
    "\n",
    "enc = lambda x: x.encode('ascii', errors='ignore')\n",
    "\n",
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "ACCESS_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "ACCESS_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'\n",
    "\n",
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print (api)\n",
    "\n",
    "#accountvar = raw_input(\"Account name: \")\n",
    "#        time.sleep(60*15)\n",
    "\n",
    "accountvar = \"vladimiralencar\"\n",
    "accountvar = \"Beyonce\"\n",
    "users = tweepy.Cursor(api.followers, screen_name=accountvar).items()\n",
    "\n",
    "print (users\n",
    "      )\n",
    "\n",
    "try:\n",
    "    user = next(users)\n",
    "    print (\"@\" + user.screen_name)\n",
    "except StopIteration:\n",
    "        print (\"exception...\")\n",
    "\n",
    "print (\"finished...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-4-0f8fa1ed00d8>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-0f8fa1ed00d8>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print \"@\" + user.screen_name\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user = next(users)\n",
    "        print \"@\" + user.screen_name\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60)\n",
    "        user = next(users)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    print \"@\" + user.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-64374bf13576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "FOLLOWING_DIR = 'following'\n",
    "MAX_FRIENDS = 200\n",
    "FRIENDS_OF_FRIENDS_LIMIT = 200\n",
    "\n",
    "#if not os.path.exists(FOLLOWING_DIR):\n",
    "#    os.makedir(\"c://tmp//twitter_python\")\n",
    "\n",
    "enc = lambda x: x.encode('ascii', errors='ignore')\n",
    "\n",
    "# The consumer keys can be found on your application's Details\n",
    "# page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "\n",
    "# The access tokens can be found on your applications's Details\n",
    "# page located at https://dev.twitter.com/apps (located\n",
    "# under \"Your access token\")\n",
    "ACCESS_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "ACCESS_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'\n",
    "\n",
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print (api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-6-2b0a3baccb37>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-2b0a3baccb37>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print 'out of depth'\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "def get_follower_ids(centre, max_depth=1, current_depth=0, taboo_list=[]):\n",
    "\n",
    "    # print 'current depth: %d, max depth: %d' % (current_depth, max_depth)\n",
    "    # print 'taboo list: ', ','.join([ str(i) for i in taboo_list ])\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        print 'out of depth'\n",
    "        return taboo_list\n",
    "\n",
    "    if centre in taboo_list:\n",
    "        # we've been here before\n",
    "        print 'Already been here.'\n",
    "        return taboo_list\n",
    "    else:\n",
    "        taboo_list.append(centre)\n",
    "\n",
    "    try:\n",
    "        userfname = os.path.join('twitter-users', str(centre) + '.json')\n",
    "        if not os.path.exists(userfname):\n",
    "            print 'Retrieving user details for twitter id %s' % str(centre)\n",
    "            while True:\n",
    "                try:\n",
    "                    user = api.get_user(centre)\n",
    "\n",
    "                    d = {'name': user.name,\n",
    "                         'screen_name': user.screen_name,\n",
    "                         'id': user.id,\n",
    "                         'friends_count': user.friends_count,\n",
    "                         'followers_count': user.followers_count,\n",
    "                         'followers_ids': user.followers_ids()}\n",
    "\n",
    "                    with open(userfname, 'w') as outf:\n",
    "                        outf.write(json.dumps(d, indent=1))\n",
    "\n",
    "                    user = d\n",
    "                    break\n",
    "                except tweepy.TweepError, error:\n",
    "                    print type(error)\n",
    "\n",
    "                    if str(error) == 'Not authorized.':\n",
    "                        print 'Can''t access user data - not authorized.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    if str(error) == 'User has been suspended.':\n",
    "                        print 'User suspended.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    errorObj = error[0][0]\n",
    "\n",
    "                    print errorObj\n",
    "\n",
    "                    if errorObj['message'] == 'Rate limit exceeded':\n",
    "                        print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "\n",
    "                    return taboo_list\n",
    "        else:\n",
    "            user = json.loads(file(userfname).read())\n",
    "\n",
    "        screen_name = enc(user['screen_name'])\n",
    "        fname = os.path.join(FOLLOWING_DIR, screen_name + '.csv')\n",
    "        friendids = []\n",
    "\n",
    "        # only retrieve friends of TED... screen names\n",
    "        if screen_name.startswith('TED'):\n",
    "            if not os.path.exists(fname):\n",
    "                print 'No cached data for screen name \"%s\"' % screen_name\n",
    "                with open(fname, 'w') as outf:\n",
    "                    params = (enc(user['name']), screen_name)\n",
    "                    print 'Retrieving friends for user \"%s\" (%s)' % params\n",
    "\n",
    "                    # page over friends\n",
    "                    c = tweepy.Cursor(api.friends, id=user['id']).items()\n",
    "\n",
    "                    friend_count = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            friend = c.next()\n",
    "                            friendids.append(friend.id)\n",
    "                            params = (friend.id, enc(friend.screen_name), enc(friend.name))\n",
    "                            outf.write('%s\\t%s\\t%s\\n' % params)\n",
    "                            friend_count += 1\n",
    "                            if friend_count >= MAX_FRIENDS:\n",
    "                                print 'Reached max no. of friends for \"%s\".' % friend.screen_name\n",
    "                                break\n",
    "                        except tweepy.TweepError:\n",
    "                            # hit rate limit, sleep for 15 minutes\n",
    "                            print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                            time.sleep(15 * 60 + 15)\n",
    "                            continue\n",
    "                        except StopIteration:\n",
    "                            break\n",
    "            else:\n",
    "                friendids = [int(line.strip().split('\\t')[0]) for line in file(fname)]\n",
    "\n",
    "            print 'Found %d friends for %s' % (len(friendids), screen_name)\n",
    "\n",
    "            # get friends of friends\n",
    "            cd = current_depth\n",
    "            if cd+1 < max_depth:\n",
    "                for fid in friendids[:FRIENDS_OF_FRIENDS_LIMIT]:\n",
    "                    taboo_list = get_follower_ids(fid, max_depth=max_depth,\n",
    "                        current_depth=cd+1, taboo_list=taboo_list)\n",
    "\n",
    "            if cd+1 < max_depth and len(friendids) > FRIENDS_OF_FRIENDS_LIMIT:\n",
    "                print 'Not all friends retrieved for %s.' % screen_name\n",
    "\n",
    "    except Exception, error:\n",
    "        print 'Error retrieving followers for user id: ', centre\n",
    "        print error\n",
    "\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "            print 'Removed file \"%s\".' % fname\n",
    "\n",
    "        sys.exit(1)\n",
    "\n",
    "    return taboo_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-s\", \"--screen-name\", required=True, help=\"Screen name of twitter user\")\n",
    "    ap.add_argument(\"-d\", \"--depth\", required=True, type=int, help=\"How far to follow user network\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    twitter_screenname = args['screen_name']\n",
    "    depth = int(args['depth'])\n",
    "\n",
    "    if depth < 1 or depth > 3:\n",
    "        print 'Depth value %d is not valid. Valid range is 1-3.' % depth\n",
    "        sys.exit('Invalid depth argument.')\n",
    "\n",
    "    print 'Max Depth: %d' % depth\n",
    "    matches = api.lookup_users(screen_names=[twitter_screenname])\n",
    "\n",
    "    if len(matches) == 1:\n",
    "        print get_follower_ids(matches[0].id, max_depth=depth)\n",
    "    else:\n",
    "        print 'Sorry, could not find twitter user with screen name: %s' % twitter_screenname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-7-334231991a2b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-334231991a2b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print 'out of depth'\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "def get_follower_ids(centre, max_depth=1, current_depth=0, taboo_list=[]):\n",
    "\n",
    "    # print 'current depth: %d, max depth: %d' % (current_depth, max_depth)\n",
    "    # print 'taboo list: ', ','.join([ str(i) for i in taboo_list ])\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        print 'out of depth'\n",
    "        return taboo_list\n",
    "\n",
    "    if centre in taboo_list:\n",
    "        # we've been here before\n",
    "        print 'Already been here.'\n",
    "        return taboo_list\n",
    "    else:\n",
    "        taboo_list.append(centre)\n",
    "\n",
    "    try:\n",
    "        userfname = os.path.join('twitter-users', str(centre) + '.json')\n",
    "        if not os.path.exists(userfname):\n",
    "            print 'Retrieving user details for twitter id %s' % str(centre)\n",
    "            while True:\n",
    "                try:\n",
    "                    user = api.get_user(centre)\n",
    "\n",
    "                    d = {'name': user.name,\n",
    "                         'screen_name': user.screen_name,\n",
    "                         'id': user.id,\n",
    "                         'friends_count': user.friends_count,\n",
    "                         'followers_count': user.followers_count,\n",
    "                         'followers_ids': user.followers_ids()}\n",
    "\n",
    "                    with open(userfname, 'w') as outf:\n",
    "                        outf.write(json.dumps(d, indent=1))\n",
    "\n",
    "                    user = d\n",
    "                    break\n",
    "                except tweepy.TweepError, error:\n",
    "                    print type(error)\n",
    "\n",
    "                    if str(error) == 'Not authorized.':\n",
    "                        print 'Can''t access user data - not authorized.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    if str(error) == 'User has been suspended.':\n",
    "                        print 'User suspended.'\n",
    "                        return taboo_list\n",
    "\n",
    "                    errorObj = error[0][0]\n",
    "\n",
    "                    print errorObj\n",
    "\n",
    "                    if errorObj['message'] == 'Rate limit exceeded':\n",
    "                        print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "\n",
    "                    return taboo_list\n",
    "        else:\n",
    "            user = json.loads(file(userfname).read())\n",
    "\n",
    "        screen_name = enc(user['screen_name'])\n",
    "        fname = os.path.join(FOLLOWING_DIR, screen_name + '.csv')\n",
    "        friendids = []\n",
    "\n",
    "        # only retrieve friends of TED... screen names\n",
    "        if screen_name.startswith('TED'):\n",
    "            if not os.path.exists(fname):\n",
    "                print 'No cached data for screen name \"%s\"' % screen_name\n",
    "                with open(fname, 'w') as outf:\n",
    "                    params = (enc(user['name']), screen_name)\n",
    "                    print 'Retrieving friends for user \"%s\" (%s)' % params\n",
    "\n",
    "                    # page over friends\n",
    "                    c = tweepy.Cursor(api.friends, id=user['id']).items()\n",
    "\n",
    "                    friend_count = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            friend = c.next()\n",
    "                            friendids.append(friend.id)\n",
    "                            params = (friend.id, enc(friend.screen_name), enc(friend.name))\n",
    "                            outf.write('%s\\t%s\\t%s\\n' % params)\n",
    "                            friend_count += 1\n",
    "                            if friend_count >= MAX_FRIENDS:\n",
    "                                print 'Reached max no. of friends for \"%s\".' % friend.screen_name\n",
    "                                break\n",
    "                        except tweepy.TweepError:\n",
    "                            # hit rate limit, sleep for 15 minutes\n",
    "                            print 'Rate limited. Sleeping for 15 minutes.'\n",
    "                            time.sleep(15 * 60 + 15)\n",
    "                            continue\n",
    "                        except StopIteration:\n",
    "                            break\n",
    "            else:\n",
    "                friendids = [int(line.strip().split('\\t')[0]) for line in file(fname)]\n",
    "\n",
    "            print 'Found %d friends for %s' % (len(friendids), screen_name)\n",
    "\n",
    "            # get friends of friends\n",
    "            cd = current_depth\n",
    "            if cd+1 < max_depth:\n",
    "                for fid in friendids[:FRIENDS_OF_FRIENDS_LIMIT]:\n",
    "                    taboo_list = get_follower_ids(fid, max_depth=max_depth,\n",
    "                        current_depth=cd+1, taboo_list=taboo_list)\n",
    "\n",
    "            if cd+1 < max_depth and len(friendids) > FRIENDS_OF_FRIENDS_LIMIT:\n",
    "                print 'Not all friends retrieved for %s.' % screen_name\n",
    "\n",
    "    except Exception, error:\n",
    "        print 'Error retrieving followers for user id: ', centre\n",
    "        print error\n",
    "\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "            print 'Removed file \"%s\".' % fname\n",
    "\n",
    "        sys.exit(1)\n",
    "\n",
    "    return taboo_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    twitter_screenname = 'Beyonce'\n",
    "    depth = 3\n",
    "\n",
    "    if depth < 1 or depth > 3:\n",
    "        print 'Depth value %d is not valid. Valid range is 1-3.' % depth\n",
    "        sys.exit('Invalid depth argument.')\n",
    "\n",
    "    print 'Max Depth: %d' % depth\n",
    "    matches = api.lookup_users(screen_names=[twitter_screenname])\n",
    "\n",
    "    if len(matches) == 1:\n",
    "        print get_follower_ids(matches[0].id, max_depth=depth)\n",
    "    else:\n",
    "        print 'Sorry, could not find twitter user with screen name: %s' % twitter_screenname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-8-661458a0da07>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-661458a0da07>\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    print \"concluido...\"\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "users = defaultdict(lambda: { 'followers': 0 })\n",
    "\n",
    "for f in glob.glob('twitter-users/*.json'):\n",
    "    data = json.load(file(f))\n",
    "    screen_name = data['screen_name']\n",
    "    users[screen_name] = { 'followers': data['followers_count'] }\n",
    "\n",
    "SEED = 'TEDxSingapore'\n",
    "\n",
    "#SEED = 'Beyonce'\n",
    "\n",
    "def process_follower_list(screen_name, edges=[], depth=0, max_depth=2):\n",
    "    f = os.path.join('following', screen_name + '.csv')\n",
    "\n",
    "    if not os.path.exists(f):\n",
    "        return edges\n",
    "\n",
    "    followers = [line.strip().split('\\t') for line in file(f)]\n",
    "\n",
    "    for follower_data in followers:\n",
    "        if len(follower_data) < 2:\n",
    "            continue\n",
    "\n",
    "        screen_name_2 = follower_data[1]\n",
    "\n",
    "        # use the number of followers for screen_name as the weight\n",
    "        weight = users[screen_name]['followers']\n",
    "\n",
    "        edges.append([screen_name, screen_name_2, weight])\n",
    "\n",
    "        if depth+1 < max_depth:\n",
    "            process_follower_list(screen_name_2, edges, depth+1, max_depth)\n",
    "\n",
    "    return edges\n",
    "\n",
    "edges = process_follower_list(SEED, max_depth=3)\n",
    "\n",
    "with open('twitter_network.csv', 'w') as outf:\n",
    "    edge_exists = {}\n",
    "    for edge in edges:\n",
    "        key = ','.join([str(x) for x in edge])\n",
    "        if not(key in edge_exists):\n",
    "            outf.write('%s\\t%s\\t%d\\n' % (edge[0], edge[1], edge[2]))\n",
    "            edge_exists[key] = True\n",
    "            \n",
    "print \"concluido...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-da71ea56e34d>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-da71ea56e34d>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    print 'g: ', len(g)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import networkx as net\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "twitter_network = [ line.strip().split('\\t') for line in file('twitter_network.csv') ]\n",
    "\n",
    "o = net.DiGraph()\n",
    "hfollowers = defaultdict(lambda: 0)\n",
    "for (twitter_user, followed_by, followers) in twitter_network:\n",
    "    o.add_edge(twitter_user, followed_by, followers=int(followers))\n",
    "    hfollowers[twitter_user] = int(followers)\n",
    "\n",
    "SEED = 'TEDxSingapore'\n",
    "\n",
    "# centre around the SEED node and set radius of graph\n",
    "g = net.DiGraph(net.ego_graph(o, SEED, radius=4))\n",
    "\n",
    "def trim_degrees_ted(g, degree=1, ted_degree=1):\n",
    "    g2 = g.copy()\n",
    "    d = net.degree(g2)\n",
    "    for n in g2.nodes():\n",
    "        if n == SEED: continue # don't prune the SEED node\n",
    "        if d[n] <= degree and not n.lower().startswith('ted'):\n",
    "            g2.remove_node(n)\n",
    "        elif n.lower().startswith('ted') and d[n] <= ted_degree:\n",
    "            g2.remove_node(n)\n",
    "    return g2\n",
    "\n",
    "def trim_edges_ted(g, weight=1, ted_weight=10):\n",
    "    g2 = net.DiGraph()\n",
    "    for f, to, edata in g.edges_iter(data=True):\n",
    "        if f == SEED or to == SEED: # keep edges that link to the SEED node\n",
    "            g2.add_edge(f, to, edata)\n",
    "        elif f.lower().startswith('ted') or to.lower().startswith('ted'):\n",
    "            if edata['followers'] >= ted_weight:\n",
    "                g2.add_edge(f, to, edata)\n",
    "        elif edata['followers'] >= weight:\n",
    "            g2.add_edge(f, to, edata)\n",
    "    return g2\n",
    "\n",
    "print 'g: ', len(g)\n",
    "core = trim_degrees_ted(g, degree=235, ted_degree=1)\n",
    "print 'core after node pruning: ', len(core)\n",
    "core = trim_edges_ted(core, weight=250000, ted_weight=35000)\n",
    "print 'core after edge pruning: ', len(core)\n",
    "\n",
    "nodeset_types = { 'TED': lambda s: s.lower().startswith('ted'), 'Not TED': lambda s: not s.lower().startswith('ted') }\n",
    "\n",
    "nodesets = defaultdict(list)\n",
    "\n",
    "for nodeset_typename, nodeset_test in nodeset_types.iteritems():\n",
    "    nodesets[nodeset_typename] = [ n for n in core.nodes_iter() if nodeset_test(n) ]\n",
    "\n",
    "pos = net.spring_layout(core) # compute layout\n",
    "\n",
    "colours = ['red','green']\n",
    "colourmap = {}\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.axis('off')\n",
    "\n",
    "# draw nodes\n",
    "i = 0\n",
    "alphas = {'TED': 0.6, 'Not TED': 0.4}\n",
    "for k in nodesets.keys():\n",
    "    ns = [ math.log10(hfollowers[n]+1) * 80 for n in nodesets[k] ]\n",
    "    print k, len(ns)\n",
    "    net.draw_networkx_nodes(core, pos, nodelist=nodesets[k], node_size=ns, node_color=colours[i], alpha=alphas[k])\n",
    "    colourmap[k] = colours[i]\n",
    "    i += 1\n",
    "print 'colourmap: ', colourmap\n",
    "\n",
    "# draw edges\n",
    "net.draw_networkx_edges(core, pos, width=0.5, alpha=0.5)\n",
    "\n",
    "# draw labels\n",
    "alphas = { 'TED': 1.0, 'Not TED': 0.5}\n",
    "for k in nodesets.keys():\n",
    "    for n in nodesets[k]:\n",
    "        x, y = pos[n]\n",
    "        plt.text(x, y+0.02, s=n, alpha=alphas[k], horizontalalignment='center', fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygraphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7e37247e6eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"Aric Hagberg (hagberg@lanl.gov)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpygraphviz\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpgv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "A simple example to create a graphviz dot file and draw a graph.\n",
    "\"\"\"\n",
    "#    Copyright (C) 2006 by \n",
    "#    Aric Hagberg <hagberg@lanl.gov>\n",
    "#    Dan Schult <dschult@colgate.edu>\n",
    "#    Manos Renieris, http://www.cs.brown.edu/~er/\n",
    "#    Distributed with BSD license.     \n",
    "#    All rights reserved, see LICENSE for details.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "__author__ = \"\"\"Aric Hagberg (hagberg@lanl.gov)\"\"\"\n",
    "\n",
    "import pygraphviz as pgv\n",
    "\n",
    "A=pgv.AGraph()\n",
    "\n",
    "A.add_edge(1,2)\n",
    "A.add_edge(2,3)\n",
    "A.add_edge(1,3)\n",
    "\n",
    "print(A.string()) # print to screen\n",
    "print(\"Wrote simple.dot\")\n",
    "A.write('simple.dot') # write to simple.dot\n",
    "\n",
    "B=pgv.AGraph('simple.dot') # create a new graph from file\n",
    "B.layout() # layout with default (neato)\n",
    "B.draw('simple.png') # draw png\n",
    "print(\"Wrote simple.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x111498748>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    # The consumer keys can be found on your application's Details\n",
    "    # page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "    CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "    CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "\n",
    "    # The access tokens can be found on your applications's Details\n",
    "    # page located at https://dev.twitter.com/apps (located\n",
    "    # under \"Your access token\")\n",
    "    OAUTH_TOKEN = ACCESS_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "    OAUTH_TOKEN_SECRET = ACCESS_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "# Sample usage\n",
    "twitter_api = oauth_login()    \n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print (twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-823c5e00c10f>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-823c5e00c10f>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    except twitter.api.TwitterHTTPError, e:\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib2 import URLError\n",
    "from httplib import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "    \n",
    "        if e.e.code == 401:\n",
    "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
    "            if sleep_when_rate_limited:\n",
    "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError, e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError, e:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"URLError encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "        except BadStatusLine, e:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "print (twitter_api)\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/users/lookup for \n",
    "# twitter_api.users.lookup\n",
    "\n",
    "response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                screen_name=\"SocialWebMining\")\n",
    "\n",
    "print (json.dumps(response, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'maxint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c9c893eab1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaxint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n\u001b[1;32m      5\u001b[0m                               friends_limit=maxint, followers_limit=maxint):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'maxint'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from sys import maxint\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=maxint, followers_limit=maxint):\n",
    "    \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/friends/ids and\n",
    "    # https://dev.twitter.com/docs/api/1.1/get/followers/ids for details\n",
    "    # on API parameters\n",
    "    \n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
    "                                count=5000)\n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "    \n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        if limit == 0: continue\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "        \n",
    "            print >> sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
    "                                                    label, (user_id or screen_name))\n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances\n",
    "        \n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    # Do something useful with the IDs, like store them to disk...\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=\"SocialWebMining\", \n",
    "                                                       friends_limit=10, \n",
    "                                                       followers_limit=10)\n",
    "\n",
    "print (friends_ids)\n",
    "print (followers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-94f9573585e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mscreen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ptwobrussell\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtwitter_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;31m#oauth_login()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids):\n",
    "    \n",
    "    friends_ids, followers_ids = set(friends_ids), set(followers_ids)\n",
    "    \n",
    "    print ('{0} is following {1}'.format(screen_name, len(friends_ids)))\n",
    "\n",
    "    print ('{0} is being followed by {1}'.format(screen_name, len(followers_ids)))\n",
    "    \n",
    "    print ('{0} of {1} are not following {2} back'.format(\n",
    "            len(friends_ids.difference(followers_ids)), \n",
    "            len(friends_ids), screen_name) )\n",
    "    \n",
    "    print ('{0} of {1} are not being followed back by {2}'.format(\n",
    "            len(followers_ids.difference(friends_ids)), \n",
    "            len(followers_ids), screen_name) )\n",
    "    \n",
    "    print ('{0} has {1} mutual friends'.format(\n",
    "            screen_name, len(friends_ids.intersection(followers_ids))) )\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "screen_name = \"ptwobrussell\"\n",
    "\n",
    "twitter_api = api #oauth_login()\n",
    "\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=screen_name)\n",
    "setwise_friends_followers_analysis(screen_name, friends_ids, followers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-b8c15a74f752>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-b8c15a74f752>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    except KeyError, e: # No more results when next_results doesn't exist\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets and \n",
    "    # https://dev.twitter.com/docs/using-search for details on advanced \n",
    "    # search criteria that may be useful for keyword arguments\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://dev.twitter.com/docs/rate-limiting/1.1/limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError, e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = \"Beyonce\"\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "        \n",
    "# Show one sample search result by slicing the list...\n",
    "print (json.dumps(results[0], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-df30797249a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprettytable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get some frequency data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtwitter_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;31m#oauth_login()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Get some frequency data\n",
    "\n",
    "twitter_api = api #oauth_login()\n",
    "search_results = twitter_search(twitter_api, q, max_results=100)\n",
    "common_entities = get_common_tweet_entities(search_results)\n",
    "\n",
    "# Use PrettyTable to create a nice tabular display\n",
    "\n",
    "pt = PrettyTable(field_names=['Entity', 'Count']) \n",
    "[ pt.add_row(kv) for kv in common_entities ]\n",
    "pt.align['Entity'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
    "print (pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = '3oTQngiUczxll9VBTOIFqhyuk'\n",
    "    CONSUMER_SECRET = 'XkmUn5j1nvdgrf4BoZcUecZJvDmzgt3iVgvNBKA0nx8LauMv1R'\n",
    "    OAUTH_TOKEN = '2904474861-kdalTd2NVus3q0PdvAiD3gB2IlF9IFZzao01ol7'\n",
    "    OAUTH_TOKEN_SECRET = '2yHMlMAEUZflpw5swYaLA8EjFyPyPJWnJT84VJoAHDKCU'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "# Sample usage\n",
    "twitter_api = oauth_login()    \n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print (twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from flask import Flask, request\n",
    "import multiprocessing\n",
    "from threading import Timer\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "from IPython.display import Javascript as JS\n",
    "\n",
    "import twitter\n",
    "from twitter.oauth_dance import parse_oauth_tokens\n",
    "from twitter.oauth import read_token_file, write_token_file\n",
    "\n",
    "# Note: This code is exactly the flow presented in the _AppendixB notebook\n",
    "\n",
    "OAUTH_FILE = \"resources/ch09-twittercookbook/twitter_oauth\"\n",
    "\n",
    "# XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "# for these credentials that you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "# on Twitter's OAuth implementation, and ensure that *oauth_callback*\n",
    "# is defined in your application settings as shown next if you are \n",
    "# using Flask in this IPython Notebook.\n",
    "\n",
    "# Define a few variables that will bleed into the lexical scope of a couple of \n",
    "# functions that follow\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "oauth_callback = 'http://127.0.0.1:5000/oauth_helper'\n",
    "    \n",
    "# Set up a callback handler for when Twitter redirects back to us after the user \n",
    "# authorizes the app\n",
    "\n",
    "webserver = Flask(\"TwitterOAuth\")\n",
    "@webserver.route(\"/oauth_helper\")\n",
    "def oauth_helper():\n",
    "    \n",
    "    oauth_verifier = request.args.get('oauth_verifier')\n",
    "\n",
    "    # Pick back up credentials from ipynb_oauth_dance\n",
    "    oauth_token, oauth_token_secret = read_token_file(OAUTH_FILE)\n",
    "    \n",
    "    _twitter = twitter.Twitter(\n",
    "        auth=twitter.OAuth(\n",
    "            oauth_token, oauth_token_secret, CONSUMER_KEY, CONSUMER_SECRET),\n",
    "        format='', api_version=None)\n",
    "\n",
    "    oauth_token, oauth_token_secret = parse_oauth_tokens(\n",
    "        _twitter.oauth.access_token(oauth_verifier=oauth_verifier))\n",
    "\n",
    "    # This web server only needs to service one request, so shut it down\n",
    "    shutdown_after_request = request.environ.get('werkzeug.server.shutdown')\n",
    "    shutdown_after_request()\n",
    "\n",
    "    # Write out the final credentials that can be picked up after the following\n",
    "    # blocking call to webserver.run().\n",
    "    write_token_file(OAUTH_FILE, oauth_token, oauth_token_secret)\n",
    "    return \"%s %s written to %s\" % (oauth_token, oauth_token_secret, OAUTH_FILE)\n",
    "\n",
    "# To handle Twitter's OAuth 1.0a implementation, we'll just need to implement a \n",
    "# custom \"oauth dance\" and will closely follow the pattern defined in \n",
    "# twitter.oauth_dance.\n",
    "\n",
    "def ipynb_oauth_dance():\n",
    "    \n",
    "    _twitter = twitter.Twitter(\n",
    "        auth=twitter.OAuth('', '', CONSUMER_KEY, CONSUMER_SECRET),\n",
    "        format='', api_version=None)\n",
    "\n",
    "    oauth_token, oauth_token_secret = parse_oauth_tokens(\n",
    "            _twitter.oauth.request_token(oauth_callback=oauth_callback))\n",
    "\n",
    "    # Need to write these interim values out to a file to pick up on the callback \n",
    "    # from Twitter that is handled by the web server in /oauth_helper\n",
    "    write_token_file(OAUTH_FILE, oauth_token, oauth_token_secret)\n",
    "    \n",
    "    oauth_url = ('http://api.twitter.com/oauth/authorize?oauth_token=' + oauth_token)\n",
    "    \n",
    "    # Tap the browser's native capabilities to access the web server through a new \n",
    "    # window to get user authorization\n",
    "    display(JS(\"window.open('%s')\" % oauth_url))\n",
    "\n",
    "# After the webserver.run() blocking call, start the OAuth Dance that will\n",
    "# ultimately cause Twitter to redirect a request back to it. Once that request\n",
    "# is serviced, the web server will shut down and program flow will resume\n",
    "# with the OAUTH_FILE containing the necessary credentials.\n",
    "Timer(1, lambda: ipynb_oauth_dance()).start()\n",
    "\n",
    "webserver.run(host='0.0.0.0')\n",
    "\n",
    "# The values that are read from this file are written out at\n",
    "# the end of /oauth_helper\n",
    "oauth_token, oauth_token_secret = read_token_file(OAUTH_FILE)\n",
    "\n",
    "# These four credentials are what is needed to authorize the application\n",
    "auth = twitter.oauth.OAuth(oauth_token, oauth_token_secret,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "print (twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import twitter\n",
    "\n",
    "def twitter_trends(twitter_api, woe_id):\n",
    "    # Prefix ID with the underscore for query string parameterization.\n",
    "    # Without the underscore, the twitter package appends the ID value\n",
    "    # to the URL itself as a special-case keyword argument.\n",
    "    return twitter_api.trends.place(_id=woe_id)\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/ for details on\n",
    "# Yahoo! Where On Earth ID\n",
    "\n",
    "WORLD_WOE_ID = 1\n",
    "world_trends = twitter_trends(twitter_api, WORLD_WOE_ID)\n",
    "print (json.dumps(world_trends, indent=1))\n",
    "\n",
    "US_WOE_ID = 23424977\n",
    "us_trends = twitter_trends(twitter_api, US_WOE_ID)\n",
    "print (json.dumps(us_trends, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[ x[name] for x in world_trends]\\\n",
    "print (world_trends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = world_trends[0]['trends']\n",
    "#type (w)\n",
    "\n",
    "print \"Assuntos mais comentados no twitter-Mundo\"\n",
    "for i in range(0,len(w)):\n",
    "    print i+1, \": \", w[i]['name']\n",
    "#print len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BR_WOE_ID = 23424768\n",
    "br_trends = twitter_trends(twitter_api, US_WOE_ID)\n",
    "#print (json.dumps(us_trends, indent=1))\n",
    "br = br_trends[0]['trends']\n",
    "\n",
    "print \"Assuntos mais comentados no twitter-Brasil\"\n",
    "for i in range(0,len(br)):\n",
    "    print i+1, \": \", br[i]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "BR_WOE_ID = 455848\n",
    "br_trends = twitter_trends(twitter_api, US_WOE_ID)\n",
    "#print (json.dumps(us_trends, indent=1))\n",
    "br = br_trends[0]['trends']\n",
    "l_br = []\n",
    "\n",
    "print \"Assuntos mais comentados no twitter-Brasil-Campina Grande\"\n",
    "for i in range(0,len(br)):\n",
    "    print i+1, \": \", br[i]['name']\n",
    "    l_br = l_br + [ br[i]['name'] ]\n",
    "print l_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CZ_WOE_ID = 796597\n",
    "cz_trends = twitter_trends(twitter_api, US_WOE_ID)\n",
    "#print (json.dumps(cz_trends, indent=1))\n",
    "cz = cz_trends[0]['trends']\n",
    "\n",
    "l_cz = []\n",
    "print \"Assuntos mais comentados no twitter-Republica Tcheca-Praga\"\n",
    "for i in range(0,len(cz)):\n",
    "    print i+1, \": \", cz[i]['name']\n",
    "    l_cz = l_cz + [ cz[i]['name'] ]\n",
    "print l_cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cz_trends br_trends\n",
    "\n",
    "# Interseo de duas listas\n",
    "# list(set(a) & set(b))\n",
    "\n",
    "l_br_trends = l_br\n",
    "l_cz_trends = l_cz\n",
    "l_br_cz = list (set(l_br_trends) & set(l_cz_trends))\n",
    "print\n",
    "print \"Nmero de trends (interseco): \" + str(len(l_br_cz))\n",
    "\n",
    "print \"Assuntos mais comentados no twitter-  Brasil/Republica Tcheca\"\n",
    "for i in range(0,len(l_br_cz)):\n",
    "    print str(i+1), \": \", l_br_cz[i]\n",
    "\n",
    "# Ordenados\n",
    "l_br_cz.sort()\n",
    "print \"Assuntos mais comentados no twitter-Brasil/Republica Tcheca\"\n",
    "for i in range(0,len(l_br_cz)):\n",
    "    print str(i+1), \": \", l_br_cz[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "\n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets and \n",
    "    # https://dev.twitter.com/docs/using-search for details on advanced \n",
    "    # search criteria that may be useful for keyword arguments\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://dev.twitter.com/docs/rate-limiting/1.1/limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError, e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = \"Beyonce\"\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "        \n",
    "# Show one sample search result by slicing the list...\n",
    "print (json.dumps(results[1], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "pp = partial(json.dumps, indent=1)\n",
    "\n",
    "twitter_world_trends = partial(twitter_trends, twitter_api, WORLD_WOE_ID)\n",
    "\n",
    "print (pp(twitter_world_trends()))\n",
    "\n",
    "authenticated_twitter_search = partial(twitter_search, twitter_api)\n",
    "results = authenticated_twitter_search(\"iPhone\")\n",
    "print (pp(results))\n",
    "\n",
    "authenticated_iphone_twitter_search = partial(authenticated_twitter_search, \"iPhone\")\n",
    "results = authenticated_iphone_twitter_search()\n",
    "print (pp(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import io, json\n",
    "\n",
    "def save_json(filename, data):\n",
    "    with io.open('{0}.json'.format(filename), \n",
    "                 'w', encoding='utf-8') as f:\n",
    "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "\n",
    "def load_json(filename):\n",
    "    with io.open('{0}.json'.format(filename), \n",
    "                 encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "q = 'Beyonce'\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "\n",
    "save_json(q, results)\n",
    "results = load_json(q)\n",
    "\n",
    "print (json.dumps(results, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (results[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (results(0)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = (json.dumps(results[1], indent=1))\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = results[1]\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (r[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = (json.dumps(results[1], indent=1))\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (r[\"urls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (r[\"entities\"][\"urls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (r[\"entities\"][\"media\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Salvar arquivos .JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, json\n",
    "\n",
    "def save_json(filename, data):\n",
    "    with io.open('{0}.json'.format(filename), \n",
    "                 'w', encoding='utf-8') as f:\n",
    "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
    "\n",
    "def load_json(filename):\n",
    "    with io.open('{0}.json'.format(filename), \n",
    "                 encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "q = 'Beyonce'\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "r = results\n",
    "\n",
    "save_json(q, results)\n",
    "results = load_json(q)\n",
    "\n",
    "print (json.dumps(results, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (type(r))\n",
    "#tweet1 = r[0]\n",
    "#print (type(tweet1))\n",
    "#print (tweet1)\n",
    "#print (json.dumps(tweet, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(json.dumps(r[0], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my_dict.items()[0]    -> (key, value) tuple of \"first\" element\n",
    "\n",
    "key, value = r.items()[0]\n",
    "print (key)\n",
    "print (value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(r.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pymongo # pip install pymongo\n",
    "\n",
    "def save_to_mongo(data, mongo_db, mongo_db_coll, **mongo_conn_kw):\n",
    "    \n",
    "    # Connects to the MongoDB server running on \n",
    "    # localhost:27017 by default\n",
    "    \n",
    "    client = pymongo.MongoClient(**mongo_conn_kw)\n",
    "    \n",
    "    # Get a reference to a particular database\n",
    "    \n",
    "    db = client[mongo_db]\n",
    "    \n",
    "    # Reference a particular collection in the database\n",
    "    \n",
    "    coll = db[mongo_db_coll]\n",
    "    \n",
    "    # Perform a bulk insert and  return the IDs\n",
    "    \n",
    "    return coll.insert(data)\n",
    "\n",
    "def load_from_mongo(mongo_db, mongo_db_coll, return_cursor=False,\n",
    "                    criteria=None, projection=None, **mongo_conn_kw):\n",
    "    \n",
    "    # Optionally, use criteria and projection to limit the data that is \n",
    "    # returned as documented in \n",
    "    # http://docs.mongodb.org/manual/reference/method/db.collection.find/\n",
    "    \n",
    "    # Consider leveraging MongoDB's aggregations framework for more \n",
    "    # sophisticated queries.\n",
    "    \n",
    "    client = pymongo.MongoClient(**mongo_conn_kw)\n",
    "    db = client[mongo_db]\n",
    "    coll = db[mongo_db_coll]\n",
    "    \n",
    "    if criteria is None:\n",
    "        criteria = {}\n",
    "    \n",
    "    if projection is None:\n",
    "        cursor = coll.find(criteria)\n",
    "    else:\n",
    "        cursor = coll.find(criteria, projection)\n",
    "\n",
    "    # Returning a cursor is recommended for large amounts of data\n",
    "    \n",
    "    if return_cursor:\n",
    "        return cursor\n",
    "    else:\n",
    "        return [ item for item in cursor ]\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "q = 'Beyonce'\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "results = twitter_search(twitter_api, q, max_results=10)\n",
    "\n",
    "save_to_mongo(results, 'search_results', q)\n",
    "\n",
    "load_from_mongo('search_results', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
