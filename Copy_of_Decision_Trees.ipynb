{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-TopicosEspeciaisEmBancoDeDados/blob/master/Copy_of_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  |  |\n",
        "|-------------|-------|\n",
        "| 🎓 **Aprendizado** | Supervisionado |\n",
        "| 📋 **Tarefa** | Classificação ou Regressão |\n",
        "| 🔧 **Normalização** | Não |\n",
        "| ⭐ **Dificuldade** | Médio |"
      ],
      "metadata": {
        "id": "emH5GRzH8qOu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74AxdJQ98XQA"
      },
      "source": [
        "# ⚙️ 0. Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82oiN_LH8XQC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.tree import (\n",
        "    DecisionTreeClassifier,\n",
        "    DecisionTreeRegressor,\n",
        "    export_graphviz,\n",
        "    export_text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYPVim4D8XQD"
      },
      "source": [
        "# 🔍 1. Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOM41wKO8XQD"
      },
      "source": [
        "**Árvores de Decisão** são um dos algoritmos de Machine Learning mais utilizados. Principalmente por que são algoritmos de fácil interpretação e não precisam de normalização dos dados para funcionarem.\n",
        "\n",
        "A ideia principal é dividir o problema em sub-problemas mais simples até que se resolva o problema. Nas árvores, cada **nó de decisão** contém um teste em um atributo, cada **folha** representa uma classe ou um valor (no caso da regressão) e o percurso da raiz até uma folha representa uma **regra de classificação/regressão**. Um atributo pode aparecer mais de uma vez na árvore, porém com valores diferentes.\n",
        "\n",
        "**Algoritmo básico:**\n",
        "1. Escolher um atributo\n",
        "2. Dividir o (sub-)banco por uma valor específico do atributo\n",
        "3. Para cada folha:\n",
        "\n",
        "    3.1: Se todos os exemplos são da mesma classe, associar essa classe aos exemplos\n",
        "    \n",
        "    3.2: Caso contrário, repetir os passos 1 a 3\n",
        "\n",
        "As **condições de paradas** podem ser inúmeras:\n",
        "- Os atributos acabaram (no caso em que os atributos não se repetem na árvore)\n",
        "- Todos os exemplos são de uma mesma classe\n",
        "- A altura da árvore atingiu um valor previamente definido\n",
        "- O número de exemplos a serem divididos é menor que um valor definido"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "✅ **Vantagens:**\n",
        "- Fáceis de entender e explicar. Mais fácil inclusive que regressão linear\n",
        "- Um dos poucos algoritmos que **não precisa de normalização**\n",
        "- Algumas pessoas acreditam que ás arvores de decisão representam a tomada de decisão mais próxima dos seres humanos.\n",
        "- Podem ser mostradas graficamente e facilmente interpretadas por não-especialistas\n",
        "\n",
        "\n",
        "❌ **Desvantagens:**\n",
        "- A precisão não é tão boa quanto outros algoritmos\n",
        "- Não são robustas. Uma pequena mudança nos dados pode causar uma grande diferença na árvore final.\n"
      ],
      "metadata": {
        "id": "uRKxv2DN-YIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "## Impureza e Ganho de Informação\n",
        "\n",
        "*Como escolher o melhor atributo?* Existem muitas medidas e algoritmos diferentes:\n",
        "- **ID3 e C4.5**: utilizam *ganho da informação*.\n",
        "- **CART**: utiliza *impureza de Gini*.\n",
        "- **CHAID**: utilizam significância estatística.\n",
        "\n",
        "Em geral, todas as abordagens concordam em dois pontos:\n",
        "- Uma divisão que mantém as proporções das classes é inútil\n",
        "- Uma divisão onde todos os exemplos são da mesma classe, tem utilidade máxima\n",
        "\n",
        "### Entropia\n",
        "A **Entropia** caracteriza a impureza de uma coleção arbitrária de exemplos.\n",
        "\n",
        "Seja $S$ uma amostra de exemplos e $p_i$ a probabilidade de cada classe $i$. A entropia $E(S)$ é definida como:\n",
        "\n",
        "$$E(S) = \\sum_i^n{p_i\\ln{p_i}}$$\n",
        "\n",
        "### Ganho de Informação\n",
        "\n",
        "O **Ganho de Informação (GI)** é a diferença entre a impureza atual (entropia, gini, etc..) e a impureza ponderada dos dois novos grupos. Intuitivamente, o **GI representa a divisão que reduz a impureza, ou seja, obtém grupos mais homogêneos em comparação com o grupo antes da divisão**. Comparando o GI para várias divisões baseadas nas regras de divisão diferente nos permite escolher a \"melhor\" divisão."
      ],
      "metadata": {
        "id": "4mCgP0hi-ael"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1cAN1SJ8XQE"
      },
      "source": [
        "# 🎲 2. Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Tempo | Temperatura | Umidade | Vento |\n",
        "|-------|-------------|---------|-------|\n",
        "| Sol | 85 | 85 | Não |\n",
        "| Sol | 80 | 90 | Sim |\n",
        "| Nublado | 83 | 86 | Não |\n",
        "| Chuva | 70 | 96 | Não |\n",
        "| Chuva | 68 | 80 | Não |\n",
        "| Chuva | 65 | 70 | Sim |\n",
        "| Nublado | 64 | 65 | Sim |\n",
        "| Sol | 72 | 95 | Não |\n",
        "| Sol | 69 | 70 | Não |\n",
        "| Chuva | 75 | 80 | Não |\n",
        "| Sol | 75 | 70 | Sim |\n",
        "| Nublado | 72 | 90 | Sim |\n",
        "| Nublado | 81 | 75 | Não |\n",
        "| Chuva | 71 | 91 | Sim |"
      ],
      "metadata": {
        "id": "6Vl0TF2lA1J5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LtlDeQu8XQE",
        "outputId": "c5b9b4cf-a983-445e-b5f3-b04ca9d25888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14, 4) (14, 1)\n"
          ]
        }
      ],
      "source": [
        "x = np.array(\n",
        "    [\n",
        "        [0, 85, 85, 0],\n",
        "        [0, 80, 90, 1],\n",
        "        [1, 83, 86, 0],\n",
        "        [2, 70, 96, 0],\n",
        "        [2, 68, 80, 0],\n",
        "        [2, 65, 70, 1],\n",
        "        [1, 64, 65, 1],\n",
        "        [0, 72, 95, 0],\n",
        "        [0, 69, 70, 0],\n",
        "        [2, 75, 80, 0],\n",
        "        [0, 75, 70, 1],\n",
        "        [1, 72, 90, 1],\n",
        "        [1, 81, 75, 0],\n",
        "        [2, 71, 91, 1]\n",
        "    ]\n",
        ")\n",
        "\n",
        "y = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]).reshape(-1, 1)\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjYL86G8XQE"
      },
      "source": [
        "# 💻 3. Implementação"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas de Impureza"
      ],
      "metadata": {
        "id": "baj5RnwX1Wzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGpeSJ1I8XQE"
      },
      "outputs": [],
      "source": [
        "def entropy(y):\n",
        "    if len(y) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    _, class_counts = np.unique(y, return_counts=True)\n",
        "    proportions = class_counts / y.shape[0]\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "def gini(y):\n",
        "    if len(y) == 0: return 0.0\n",
        "\n",
        "    _, class_counts = np.unique(y, return_counts=True)\n",
        "    proportions = class_counts / y.shape[0]\n",
        "    return 1.0 - np.sum(proportions**2)\n",
        "\n",
        "\n",
        "def mse(y: np.ndarray):\n",
        "    if len(y) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    mean_y = np.mean(y)\n",
        "    return np.mean((y - mean_y) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_as_text(node, feature_names, indent=''):\n",
        "    if node.is_leaf: return 'Leaf: y = {}\\n'.format(node.output)\n",
        "\n",
        "    is_discrete = isinstance(node.value, str)\n",
        "    right_condition = f\"{feature_names[node.col_index]} {'==' if is_discrete else '>='} {node.value} | \"\n",
        "    left_condition = indent\n",
        "    left_condition += f\"{feature_names[node.col_index]} {'!=' if is_discrete else '< '} {node.value} | \"\n",
        "\n",
        "    summary = right_condition + tree_as_text(node.right_child, feature_names, indent + ' '*len(right_condition))\n",
        "    summary += left_condition + tree_as_text(node.left_child, feature_names, indent + ' '*len(right_condition))\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "Rhe67sbQz-Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmxf7FWJ8XQE"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, parent=None):\n",
        "        self.parent = parent\n",
        "        self.left_child = None   # less than a value (regression) OR not equal to a category (classification)\n",
        "        self.right_child = None  # otherwise\n",
        "        self.impurity = None\n",
        "        self.col_index = None\n",
        "        self.value = None\n",
        "        self.is_leaf = True\n",
        "        self.output = None\n",
        "\n",
        "\n",
        "class BaseTree():\n",
        "    def __init__(self, criterion=gini, max_depth=None, min_samples_split=2):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = np.inf if max_depth is None else max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = Node()\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self._build_tree(self.root, x, y)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.array([self._predict_recursive(sample, self.root) for sample in x])\n",
        "\n",
        "    def _compute_output(self, y):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _build_tree(self, parent_node, x, y, depth=0):\n",
        "        parent_node.col_index, parent_node.value, parent_node.impurity = self._find_best_split(x, y)\n",
        "        if (\n",
        "            parent_node.impurity == 0\n",
        "            or len(y) < self.min_samples_split\n",
        "            or depth > self.max_depth\n",
        "        ):\n",
        "            parent_node.output = self._compute_output(y)\n",
        "            return\n",
        "\n",
        "        x_left, y_left, x_right, y_right = self._split_data(x, y, parent_node.col_index, parent_node.value)\n",
        "\n",
        "        left_child = Node(parent=parent_node)\n",
        "        self._build_tree(left_child, x_left, y_left, depth + 1)\n",
        "\n",
        "        right_child = Node(parent=parent_node)\n",
        "        self._build_tree(right_child, x_right, y_right, depth + 1)\n",
        "\n",
        "        parent_node.is_leaf = False\n",
        "        parent_node.left_child = left_child\n",
        "        parent_node.right_child = right_child\n",
        "\n",
        "\n",
        "    def _find_best_split(self, x, y):\n",
        "        best_impurity, best_col, best_value = 0.0, None, None\n",
        "\n",
        "        n_features = x.shape[1]\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = np.unique(x[:, feature_idx])\n",
        "            for value in feature_values:\n",
        "                gain = self._information_gain(x, y, feature_idx, value)\n",
        "                if gain > best_impurity:\n",
        "                    best_impurity = gain\n",
        "                    best_col = feature_idx\n",
        "                    best_value = value\n",
        "\n",
        "        return best_col, best_value, best_impurity\n",
        "\n",
        "    def _information_gain(self, x, y, col_index, threshold):\n",
        "        parent_impurity = self.criterion(y)\n",
        "\n",
        "        _, y_left, _, y_right = self._split_data(x, y, col_index, threshold)\n",
        "        if len(y_left) == 0 or len(y_right) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        left_impurity = self.criterion(y_left)\n",
        "        right_impurity = self.criterion(y_right)\n",
        "        p = len(y_left) / y.shape[0]\n",
        "        child_impurity = p * left_impurity + (1 - p) * right_impurity\n",
        "\n",
        "        gain = parent_impurity - child_impurity\n",
        "        return gain\n",
        "\n",
        "    def _split_data(self, x, y, col_index, threshold):\n",
        "        left_mask = x[:, col_index] < threshold\n",
        "        right_mask = np.invert(left_mask)\n",
        "        return x[left_mask], y[left_mask], x[right_mask], y[right_mask]\n",
        "\n",
        "    def _predict_recursive(self, x, node):\n",
        "        if node.is_leaf: return node.output\n",
        "\n",
        "        right_condition = x[node.col_index] > node.value\n",
        "        return self._predict_recursive(x, node.right_child if right_condition else node.left_child)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏷️ Classificador"
      ],
      "metadata": {
        "id": "IMrk_KkI1eyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DTClassifier(BaseTree):\n",
        "    def _compute_output(self, y):\n",
        "        classes, class_counts = np.unique(y, return_counts=True)\n",
        "        return classes[np.argmax(class_counts)]"
      ],
      "metadata": {
        "id": "WCMq7CKn1giH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DTClassifier(max_depth=3)\n",
        "dt.fit(x, y)\n",
        "\n",
        "y_pred = dt.predict(x)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxqo8S0Q1u9c",
        "outputId": "8bb897c1-f2fe-46a0-efc5-cdb2ea479f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 1 1 0 1 1 1 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparação com o Scikit-learn"
      ],
      "metadata": {
        "id": "F_kVm6aP1iuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_clf, y_clf = make_classification(n_samples=1000, n_features=4, n_classes=2, n_redundant=0, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_clf, y_clf, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DTClassifier(criterion=gini, max_depth=5, min_samples_split=2)\n",
        "dt.fit(x_train, y_train)\n",
        "accuracy = accuracy_score(y_test, dt.predict(x_test))\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "sk_dt = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=2, random_state=42)\n",
        "sk_dt.fit(x_train, y_train)\n",
        "sk_accuracy = accuracy_score(y_test, sk_dt.predict(x_test))\n",
        "print(f\" Sklearn: {sk_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0pFW49261w",
        "outputId": "70aa08ce-1214-49be-f891-593b0cde0b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.910\n",
            " Sklearn: 0.910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📈 Regressor"
      ],
      "metadata": {
        "id": "RKRY-EBc3tqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DTRegressor(BaseTree):\n",
        "    def _compute_output(self, y):\n",
        "        return np.mean(y)"
      ],
      "metadata": {
        "id": "8B9Mmdl-3M6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF1SQfYL8XQF"
      },
      "source": [
        "### Comparação com o Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reg, y_reg = make_regression(n_samples=1000, n_features=4, n_targets=1, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DTRegressor(criterion=mse, max_depth=5, min_samples_split=2)\n",
        "dt.fit(x_train, y_train)\n",
        "error = mean_squared_error(y_test, dt.predict(x_test))\n",
        "print(f\"MSE: {error:.3f}\")\n",
        "\n",
        "sk_dt = DecisionTreeRegressor(criterion='squared_error', max_depth=5, min_samples_split=2, random_state=42)\n",
        "sk_dt.fit(x_train, y_train)\n",
        "sk_error = mean_squared_error(y_test, sk_dt.predict(x_test))\n",
        "print(f\"MSE: {sk_error:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUDakfaL2ko7",
        "outputId": "3b1d785d-ef1a-4eb8-df1d-1506fe9c2f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2369.947\n",
            "MSE: 2627.595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💭 Considerações Finais"
      ],
      "metadata": {
        "id": "t5Zyk7cj4G3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A implementação do scikit-learn depende de um `random_state`. Logo, é difícil fazer todos os resultados baterem sempre.\n",
        "\n",
        "**random_state**: Controls the randomness of the estimator. The features are always randomly permuted at each split, even if splitter is set to \"best\". When max_features < n_features, the algorithm will select max_features at random at each split before finding the best split among them. **But the best found split may vary across different runs, even if max_features=n_features**. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.\n"
      ],
      "metadata": {
        "id": "9lYsrJlK6KKM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCZlNzmcA9wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}