{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/Alunos-UEPB-TopicosEspeciaisEmBancoDeDados/blob/master/Copy_of_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  |  |\n",
        "|-------------|-------|\n",
        "| üéì **Aprendizado** | Supervisionado |\n",
        "| üìã **Tarefa** | Classifica√ß√£o ou Regress√£o |\n",
        "| üîß **Normaliza√ß√£o** | N√£o |\n",
        "| ‚≠ê **Dificuldade** | M√©dio |"
      ],
      "metadata": {
        "id": "emH5GRzH8qOu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74AxdJQ98XQA"
      },
      "source": [
        "# ‚öôÔ∏è 0. Depend√™ncias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82oiN_LH8XQC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.tree import (\n",
        "    DecisionTreeClassifier,\n",
        "    DecisionTreeRegressor,\n",
        "    export_graphviz,\n",
        "    export_text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYPVim4D8XQD"
      },
      "source": [
        "# üîç 1. Introdu√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOM41wKO8XQD"
      },
      "source": [
        "**√Årvores de Decis√£o** s√£o um dos algoritmos de Machine Learning mais utilizados. Principalmente por que s√£o algoritmos de f√°cil interpreta√ß√£o e n√£o precisam de normaliza√ß√£o dos dados para funcionarem.\n",
        "\n",
        "A ideia principal √© dividir o problema em sub-problemas mais simples at√© que se resolva o problema. Nas √°rvores, cada **n√≥ de decis√£o** cont√©m um teste em um atributo, cada **folha** representa uma classe ou um valor (no caso da regress√£o) e o percurso da raiz at√© uma folha representa uma **regra de classifica√ß√£o/regress√£o**. Um atributo pode aparecer mais de uma vez na √°rvore, por√©m com valores diferentes.\n",
        "\n",
        "**Algoritmo b√°sico:**\n",
        "1. Escolher um atributo\n",
        "2. Dividir o (sub-)banco por uma valor espec√≠fico do atributo\n",
        "3. Para cada folha:\n",
        "\n",
        "    3.1: Se todos os exemplos s√£o da mesma classe, associar essa classe aos exemplos\n",
        "    \n",
        "    3.2: Caso contr√°rio, repetir os passos 1 a 3\n",
        "\n",
        "As **condi√ß√µes de paradas** podem ser in√∫meras:\n",
        "- Os atributos acabaram (no caso em que os atributos n√£o se repetem na √°rvore)\n",
        "- Todos os exemplos s√£o de uma mesma classe\n",
        "- A altura da √°rvore atingiu um valor previamente definido\n",
        "- O n√∫mero de exemplos a serem divididos √© menor que um valor definido"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "‚úÖ **Vantagens:**\n",
        "- F√°ceis de entender e explicar. Mais f√°cil inclusive que regress√£o linear\n",
        "- Um dos poucos algoritmos que **n√£o precisa de normaliza√ß√£o**\n",
        "- Algumas pessoas acreditam que √°s arvores de decis√£o representam a tomada de decis√£o mais pr√≥xima dos seres humanos.\n",
        "- Podem ser mostradas graficamente e facilmente interpretadas por n√£o-especialistas\n",
        "\n",
        "\n",
        "‚ùå **Desvantagens:**\n",
        "- A precis√£o n√£o √© t√£o boa quanto outros algoritmos\n",
        "- N√£o s√£o robustas. Uma pequena mudan√ßa nos dados pode causar uma grande diferen√ßa na √°rvore final.\n"
      ],
      "metadata": {
        "id": "uRKxv2DN-YIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "## Impureza e Ganho de Informa√ß√£o\n",
        "\n",
        "*Como escolher o melhor atributo?* Existem muitas medidas e algoritmos diferentes:\n",
        "- **ID3 e C4.5**: utilizam *ganho da informa√ß√£o*.\n",
        "- **CART**: utiliza *impureza de Gini*.\n",
        "- **CHAID**: utilizam signific√¢ncia estat√≠stica.\n",
        "\n",
        "Em geral, todas as abordagens concordam em dois pontos:\n",
        "- Uma divis√£o que mant√©m as propor√ß√µes das classes √© in√∫til\n",
        "- Uma divis√£o onde todos os exemplos s√£o da mesma classe, tem utilidade m√°xima\n",
        "\n",
        "### Entropia\n",
        "A **Entropia** caracteriza a impureza de uma cole√ß√£o arbitr√°ria de exemplos.\n",
        "\n",
        "Seja $S$ uma amostra de exemplos e $p_i$ a probabilidade de cada classe $i$. A entropia $E(S)$ √© definida como:\n",
        "\n",
        "$$E(S) = \\sum_i^n{p_i\\ln{p_i}}$$\n",
        "\n",
        "### Ganho de Informa√ß√£o\n",
        "\n",
        "O **Ganho de Informa√ß√£o (GI)** √© a diferen√ßa entre a impureza atual (entropia, gini, etc..) e a impureza ponderada dos dois novos grupos. Intuitivamente, o **GI representa a divis√£o que reduz a impureza, ou seja, obt√©m grupos mais homog√™neos em compara√ß√£o com o grupo antes da divis√£o**. Comparando o GI para v√°rias divis√µes baseadas nas regras de divis√£o diferente nos permite escolher a \"melhor\" divis√£o."
      ],
      "metadata": {
        "id": "4mCgP0hi-ael"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1cAN1SJ8XQE"
      },
      "source": [
        "# üé≤ 2. Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Tempo | Temperatura | Umidade | Vento |\n",
        "|-------|-------------|---------|-------|\n",
        "| Sol | 85 | 85 | N√£o |\n",
        "| Sol | 80 | 90 | Sim |\n",
        "| Nublado | 83 | 86 | N√£o |\n",
        "| Chuva | 70 | 96 | N√£o |\n",
        "| Chuva | 68 | 80 | N√£o |\n",
        "| Chuva | 65 | 70 | Sim |\n",
        "| Nublado | 64 | 65 | Sim |\n",
        "| Sol | 72 | 95 | N√£o |\n",
        "| Sol | 69 | 70 | N√£o |\n",
        "| Chuva | 75 | 80 | N√£o |\n",
        "| Sol | 75 | 70 | Sim |\n",
        "| Nublado | 72 | 90 | Sim |\n",
        "| Nublado | 81 | 75 | N√£o |\n",
        "| Chuva | 71 | 91 | Sim |"
      ],
      "metadata": {
        "id": "6Vl0TF2lA1J5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LtlDeQu8XQE",
        "outputId": "c5b9b4cf-a983-445e-b5f3-b04ca9d25888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14, 4) (14, 1)\n"
          ]
        }
      ],
      "source": [
        "x = np.array(\n",
        "    [\n",
        "        [0, 85, 85, 0],\n",
        "        [0, 80, 90, 1],\n",
        "        [1, 83, 86, 0],\n",
        "        [2, 70, 96, 0],\n",
        "        [2, 68, 80, 0],\n",
        "        [2, 65, 70, 1],\n",
        "        [1, 64, 65, 1],\n",
        "        [0, 72, 95, 0],\n",
        "        [0, 69, 70, 0],\n",
        "        [2, 75, 80, 0],\n",
        "        [0, 75, 70, 1],\n",
        "        [1, 72, 90, 1],\n",
        "        [1, 81, 75, 0],\n",
        "        [2, 71, 91, 1]\n",
        "    ]\n",
        ")\n",
        "\n",
        "y = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]).reshape(-1, 1)\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjYL86G8XQE"
      },
      "source": [
        "# üíª 3. Implementa√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M√©tricas de Impureza"
      ],
      "metadata": {
        "id": "baj5RnwX1Wzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGpeSJ1I8XQE"
      },
      "outputs": [],
      "source": [
        "def entropy(y):\n",
        "    if len(y) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    _, class_counts = np.unique(y, return_counts=True)\n",
        "    proportions = class_counts / y.shape[0]\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "def gini(y):\n",
        "    if len(y) == 0: return 0.0\n",
        "\n",
        "    _, class_counts = np.unique(y, return_counts=True)\n",
        "    proportions = class_counts / y.shape[0]\n",
        "    return 1.0 - np.sum(proportions**2)\n",
        "\n",
        "\n",
        "def mse(y: np.ndarray):\n",
        "    if len(y) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    mean_y = np.mean(y)\n",
        "    return np.mean((y - mean_y) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_as_text(node, feature_names, indent=''):\n",
        "    if node.is_leaf: return 'Leaf: y = {}\\n'.format(node.output)\n",
        "\n",
        "    is_discrete = isinstance(node.value, str)\n",
        "    right_condition = f\"{feature_names[node.col_index]} {'==' if is_discrete else '>='} {node.value} | \"\n",
        "    left_condition = indent\n",
        "    left_condition += f\"{feature_names[node.col_index]} {'!=' if is_discrete else '< '} {node.value} | \"\n",
        "\n",
        "    summary = right_condition + tree_as_text(node.right_child, feature_names, indent + ' '*len(right_condition))\n",
        "    summary += left_condition + tree_as_text(node.left_child, feature_names, indent + ' '*len(right_condition))\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "Rhe67sbQz-Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pmxf7FWJ8XQE"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "    def __init__(self, parent=None):\n",
        "        self.parent = parent\n",
        "        self.left_child = None   # less than a value (regression) OR not equal to a category (classification)\n",
        "        self.right_child = None  # otherwise\n",
        "        self.impurity = None\n",
        "        self.col_index = None\n",
        "        self.value = None\n",
        "        self.is_leaf = True\n",
        "        self.output = None\n",
        "\n",
        "\n",
        "class BaseTree():\n",
        "    def __init__(self, criterion=gini, max_depth=None, min_samples_split=2):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = np.inf if max_depth is None else max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = Node()\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self._build_tree(self.root, x, y)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.array([self._predict_recursive(sample, self.root) for sample in x])\n",
        "\n",
        "    def _compute_output(self, y):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _build_tree(self, parent_node, x, y, depth=0):\n",
        "        parent_node.col_index, parent_node.value, parent_node.impurity = self._find_best_split(x, y)\n",
        "        if (\n",
        "            parent_node.impurity == 0\n",
        "            or len(y) < self.min_samples_split\n",
        "            or depth > self.max_depth\n",
        "        ):\n",
        "            parent_node.output = self._compute_output(y)\n",
        "            return\n",
        "\n",
        "        x_left, y_left, x_right, y_right = self._split_data(x, y, parent_node.col_index, parent_node.value)\n",
        "\n",
        "        left_child = Node(parent=parent_node)\n",
        "        self._build_tree(left_child, x_left, y_left, depth + 1)\n",
        "\n",
        "        right_child = Node(parent=parent_node)\n",
        "        self._build_tree(right_child, x_right, y_right, depth + 1)\n",
        "\n",
        "        parent_node.is_leaf = False\n",
        "        parent_node.left_child = left_child\n",
        "        parent_node.right_child = right_child\n",
        "\n",
        "\n",
        "    def _find_best_split(self, x, y):\n",
        "        best_impurity, best_col, best_value = 0.0, None, None\n",
        "\n",
        "        n_features = x.shape[1]\n",
        "        for feature_idx in range(n_features):\n",
        "            feature_values = np.unique(x[:, feature_idx])\n",
        "            for value in feature_values:\n",
        "                gain = self._information_gain(x, y, feature_idx, value)\n",
        "                if gain > best_impurity:\n",
        "                    best_impurity = gain\n",
        "                    best_col = feature_idx\n",
        "                    best_value = value\n",
        "\n",
        "        return best_col, best_value, best_impurity\n",
        "\n",
        "    def _information_gain(self, x, y, col_index, threshold):\n",
        "        parent_impurity = self.criterion(y)\n",
        "\n",
        "        _, y_left, _, y_right = self._split_data(x, y, col_index, threshold)\n",
        "        if len(y_left) == 0 or len(y_right) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        left_impurity = self.criterion(y_left)\n",
        "        right_impurity = self.criterion(y_right)\n",
        "        p = len(y_left) / y.shape[0]\n",
        "        child_impurity = p * left_impurity + (1 - p) * right_impurity\n",
        "\n",
        "        gain = parent_impurity - child_impurity\n",
        "        return gain\n",
        "\n",
        "    def _split_data(self, x, y, col_index, threshold):\n",
        "        left_mask = x[:, col_index] < threshold\n",
        "        right_mask = np.invert(left_mask)\n",
        "        return x[left_mask], y[left_mask], x[right_mask], y[right_mask]\n",
        "\n",
        "    def _predict_recursive(self, x, node):\n",
        "        if node.is_leaf: return node.output\n",
        "\n",
        "        right_condition = x[node.col_index] > node.value\n",
        "        return self._predict_recursive(x, node.right_child if right_condition else node.left_child)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üè∑Ô∏è Classificador"
      ],
      "metadata": {
        "id": "IMrk_KkI1eyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DTClassifier(BaseTree):\n",
        "    def _compute_output(self, y):\n",
        "        classes, class_counts = np.unique(y, return_counts=True)\n",
        "        return classes[np.argmax(class_counts)]"
      ],
      "metadata": {
        "id": "WCMq7CKn1giH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DTClassifier(max_depth=3)\n",
        "dt.fit(x, y)\n",
        "\n",
        "y_pred = dt.predict(x)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxqo8S0Q1u9c",
        "outputId": "8bb897c1-f2fe-46a0-efc5-cdb2ea479f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 1 1 0 1 1 1 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compara√ß√£o com o Scikit-learn"
      ],
      "metadata": {
        "id": "F_kVm6aP1iuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_clf, y_clf = make_classification(n_samples=1000, n_features=4, n_classes=2, n_redundant=0, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_clf, y_clf, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DTClassifier(criterion=gini, max_depth=5, min_samples_split=2)\n",
        "dt.fit(x_train, y_train)\n",
        "accuracy = accuracy_score(y_test, dt.predict(x_test))\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "sk_dt = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=2, random_state=42)\n",
        "sk_dt.fit(x_train, y_train)\n",
        "sk_accuracy = accuracy_score(y_test, sk_dt.predict(x_test))\n",
        "print(f\" Sklearn: {sk_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0pFW49261w",
        "outputId": "70aa08ce-1214-49be-f891-593b0cde0b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.910\n",
            " Sklearn: 0.910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Regressor"
      ],
      "metadata": {
        "id": "RKRY-EBc3tqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DTRegressor(BaseTree):\n",
        "    def _compute_output(self, y):\n",
        "        return np.mean(y)"
      ],
      "metadata": {
        "id": "8B9Mmdl-3M6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF1SQfYL8XQF"
      },
      "source": [
        "### Compara√ß√£o com o Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reg, y_reg = make_regression(n_samples=1000, n_features=4, n_targets=1, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DTRegressor(criterion=mse, max_depth=5, min_samples_split=2)\n",
        "dt.fit(x_train, y_train)\n",
        "error = mean_squared_error(y_test, dt.predict(x_test))\n",
        "print(f\"MSE: {error:.3f}\")\n",
        "\n",
        "sk_dt = DecisionTreeRegressor(criterion='squared_error', max_depth=5, min_samples_split=2, random_state=42)\n",
        "sk_dt.fit(x_train, y_train)\n",
        "sk_error = mean_squared_error(y_test, sk_dt.predict(x_test))\n",
        "print(f\"MSE: {sk_error:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUDakfaL2ko7",
        "outputId": "3b1d785d-ef1a-4eb8-df1d-1506fe9c2f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2369.947\n",
            "MSE: 2627.595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí≠ Considera√ß√µes Finais"
      ],
      "metadata": {
        "id": "t5Zyk7cj4G3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A implementa√ß√£o do scikit-learn depende de um `random_state`. Logo, √© dif√≠cil fazer todos os resultados baterem sempre.\n",
        "\n",
        "**random_state**: Controls the randomness of the estimator. The features are always randomly permuted at each split, even if splitter is set to \"best\". When max_features < n_features, the algorithm will select max_features at random at each split before finding the best split among them. **But the best found split may vary across different runs, even if max_features=n_features**. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.\n"
      ],
      "metadata": {
        "id": "9lYsrJlK6KKM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCZlNzmcA9wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}