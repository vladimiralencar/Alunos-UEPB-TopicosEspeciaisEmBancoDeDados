{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de Atributos (variáveis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionar os melhores atributos, depois treinar o modelo e aplicar as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Criando um modelo\n",
    "from sklearn import linear_model\n",
    "\n",
    "def calcula_metricas(dataset, atributos_selecionados):\n",
    "\n",
    "    X = dataset.loc[:, atributos_selecionados ].values\n",
    "    y = dataset['target'].values\n",
    "\n",
    "    modelo = linear_model.LinearRegression() \n",
    "    modelo.fit(X,y)\n",
    "\n",
    "    # MAE - Mean Absolute Error\n",
    "    from sklearn import model_selection\n",
    "    kfold = 10\n",
    "    resultado = model_selection.cross_val_score(modelo, X, y, cv = kfold, \n",
    "                                                scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "    # Print do resultado\n",
    "    print(\"MAE: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))\n",
    "\n",
    "    # MSE - Mean Squared Error\n",
    "    # Definindo os valores para o número de folds\n",
    "    num_folds = 10\n",
    "    num_instances = len(X)\n",
    "    seed = 7\n",
    "\n",
    "    # Separando os dados em folds\n",
    "    kfold = model_selection.KFold(num_folds, True, random_state = seed)\n",
    "\n",
    "    resultado = model_selection.cross_val_score(modelo, X, y, cv = kfold, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "    # Print do resultado\n",
    "    print(\"MSE: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))\n",
    "\n",
    "    # RMSE (Root Mean Squared Error\n",
    "    from math import sqrt\n",
    "    print(\"RMSE: %.3f \" % (sqrt(abs(resultado.mean()))))\n",
    "\n",
    "    # R2\n",
    "    resultado = model_selection.cross_val_score(modelo, X, y, cv = kfold, scoring = 'r2')\n",
    "\n",
    "    # Print do resultado\n",
    "    print(\"R^2: %.3f (%.3f)\" % (resultado.mean(), resultado.std()))\n",
    "\n",
    "# Seleciona os atributos\n",
    "atributos_selecionados = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', # 'DIS', \n",
    "                              'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'] # 'AGE',\n",
    "\n",
    "#calcula_metricas(dataset, atributos_selecionados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset Boston Houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-residential acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per 10,000 \n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population \n",
    "14. TARGET: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Atributos - Utilizando RFE - Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica para seleção de atributos, que recursivamente remove os atributos e constrói o modelo com os atributos remanescentes. <br> Esta técnica utiliza a acurácia do modelo para identificar os atributos que mais contribuem para prever a variável alvo. <br> Em inglês esta técnica é chamada Recursive Feature Elimination (RFE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o dataset\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de Atributos:', len(dataset.columns) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando a RFE para Seleção dos Melhores Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# aplicando a RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset['target'].values\n",
    "\n",
    "num_atributos_relevantes = 8\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, num_atributos_relevantes, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "print(\"Num Features: \", selector.n_features_)\n",
    "\n",
    "print(dataset.columns)\n",
    "print(\"Selected Features: \", selector.support_)\n",
    "print(\"Feature Ranking: \", selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos = pd.DataFrame( {'Atributo': dataset.columns[:-1],\n",
    "                              'Importancia': selector.ranking_ })\n",
    "                             \n",
    "dfatributos = dfatributos.sort_values(by='Importancia', ascending=True)\n",
    "dfatributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos.Atributo.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modelo com 13 atributos\")\n",
    "atributos_selecionados = ['CRIM', 'INDUS', 'CHAS', 'NOX', 'RM', 'DIS', 'PTRATIO', 'LSTAT',\n",
    "       'ZN', 'AGE', 'B', 'RAD', 'TAX']\n",
    "calcula_metricas(dataset, atributos_selecionados)\n",
    "\n",
    "print(\"\\nModelo com atributos selecionados com RFE\")\n",
    "# Seleciona os atributos\n",
    "atributos_selecionados = ['CRIM', 'INDUS', 'CHAS', 'NOX', 'RM', 'DIS', 'PTRATIO', 'LSTAT']\n",
    "       #'ZN', 'AGE', 'B', 'RAD', 'TAX']\n",
    "\n",
    "calcula_metricas(dataset, atributos_selecionados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Atributos -  Seleciona os atributos pela variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(X)\n",
    "selector.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos2 = pd.DataFrame( {'Atributo': dataset.columns[:-1],\n",
    "                              'Importancia': selector.variances_  })\n",
    "                             \n",
    "dfatributos2 = dfatributos2.sort_values(by='Importancia', ascending=True).reset_index(drop=True)\n",
    "dfatributos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos2.Atributo.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modelo com 13 atributos\")\n",
    "atributos_selecionados = ['NOX', 'CHAS', 'RM', 'DIS', 'PTRATIO', 'RAD', 'INDUS', 'LSTAT',\n",
    "       'CRIM', 'AGE', 'ZN', 'B', 'TAX']\n",
    "calcula_metricas(dataset, atributos_selecionados)\n",
    "\n",
    "print(\"\\nModelo com atributos selecionados com VarianceThreshold\")\n",
    "# Seleciona os atributos\n",
    "atributos_selecionados = ['NOX', 'CHAS', 'RM', 'DIS', 'PTRATIO', 'RAD', 'INDUS', 'LSTAT',\n",
    "       'CRIM', 'AGE'] #'ZN', 'B', 'TAX']\n",
    "\n",
    "calcula_metricas(dataset, atributos_selecionados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Atributos - Utilizando Árvores de Decisão "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Decision Trees, como o algoritmo RandomForest, podem ser usados para estimar a importância de cada atributo. Esse método retorna um score para cada atributo.\n",
    "\n",
    "Quanto maior o score, maior a importância do atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=30, max_depth=6)\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos3 = pd.DataFrame( {'Atributo': dataset.columns[:-1],\n",
    "                              'Importancia': clf.feature_importances_  })\n",
    "                             \n",
    "dfatributos3 = dfatributos3.sort_values(by='Importancia', ascending=False)\n",
    "dfatributos3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 1-A: Criar o modelo e as métricas, comparando com o modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Atributos - Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfatributos4 = pd.DataFrame( {'Atributo': dataset.columns[:-1],\n",
    "                              'Importancia': model.feature_importances_ })\n",
    "                             \n",
    "dfatributos4 = dfatributos3.sort_values(by='Importancia', ascending=False).reset_index(drop=True)\n",
    "dfatributos4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona os atributos\n",
    "atributos_selecionados = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', # 'DIS', \n",
    "                              'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'] # 'AGE',\n",
    "\n",
    "calcula_metricas(dataset, atributos_selecionados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 1-B: Criar o modelo e as métricas, comparando com o modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
